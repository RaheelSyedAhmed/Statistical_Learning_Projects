log_fit <- glm(Default ~ ., data = remaining_train, family="binomial")
prob <- predict(log_fit, excluded_subject, type="response")
if(prob >= 0.5){
pred = T
}
else{
pred = F
}
err <- 1 - (pred == excluded_subject$Default)
sum_misclass <- sum_misclass + err
}
(sum_misclass / nrow(german_data))
cost <- function(r, pi = 0){mean(abs(r - pi) > 0.5)}
all_lr.err <- cv.glm(german_data, all_lr, cost, K=nrow(german_data))
all_lr.err$delta
levels(german_data[,7])
knn.cross <- tune.knn(x = german_data[,-1], y = german_data[,1], k = 1:50,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
str(german_data)
as.numeric(german_data[,7])
knn.cross <- tune.knn(x = german_data[,-1], y = german_data[,1], k = 1:50,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
as.numeric(german_data[,2])
as.numeric(german_data[,3])
as.numeric(german_data[,4])
as.numeric(german_data[,5])
as.numeric(german_data[,6])
as.numeric(german_data[,7])
as.numeric(german_data[,8])
View(german_data)
german_data[,c(2,4,5,7,8,10,11,13,15,16,20,21)]
as.numeric(german_data[,c(2,4,5,7,8,10,11,13,15,16,20,21)])
?sapply
sapply(german_data[,c(2,4,5,7,8,10,11,13,15,16,20,21)], as.numeric)
german_data[,c(2,4,5,7,8,10,11,13,15,16,20,21)] <- sapply(german_data[,c(2,4,5,7,8,10,11,13,15,16,20,21)], as.numeric)
german_data
knn.cross <- tune.knn(x = german_data[,-1], y = german_data[,1], k = 1:50,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)] <- sapply(german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)], as.numeric)
german_data
knn.cross <- tune.knn(x = german_data[,-1], y = german_data[,1], k = 1:50,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
str(german_data)
as.factor(german_data[,1])
knn.cross <- tune.knn(x = german_data[,-1], y = as.factor(german_data[,1]), k = 1:50,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
knn.cross <- tune.knn(x = german_data[,-1], y = as.factor(german_data[,1]), k = 1:200,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
summary(knn.cross)
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K)
library(class)
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K)
optim_K <- 38
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K)
classifier_knn
table(german_data$Default, classifier_knn)
table(classifier_knn, german_data$Default)
1 - mean(classifier_knn == german_data$Default)
table(classifier_knn, german_data$Default)
table(all_lr.pred, german_data$Default)
c(26/(26+274), (688/(688+12)))
all_lr.err$delta
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
1 - mean(classifier_knn == german_data$Default)
table(classifier_knn, german_data$Default)
c(25/(25+275), (689/(689+11)))
classifier_knn
knn_probs <- attr(classifier_knn, "prob")
roc.knn <- roc(german_data$Default, knn_probs)
roc.knn
plot(roc.all_lr, legacy.axes=T)
library(MASS)
qda.fit <- qda(Default ~ ., data = german_data)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
View(qda.pred)
knn.cross <- tune.knn(x = german_data[,-1], y = as.factor(german_data[,1]), k = 1:200,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
summary(knn.cross)
knn.cross <- tune.knn(x = german_data[,-1], y = as.factor(german_data[,1]), k = 1:200,tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
summary(knn.cross)
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
knn_probs <- attr(classifier_knn, "prob")
1 - mean(classifier_knn == german_data$Default)
table(classifier_knn, german_data$Default)
c(25/(25+275), (689/(689+11)))
roc.knn <- roc(german_data$Default, knn_probs)
roc.knn
plot(roc.all_lr, legacy.axes=T)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
1 - mean(qda.pred == german_data$Default)
View(qda.pred)
1 - mean(qda.pred$class == german_data$Default)
table(qda.pred$class, german_data$Default)
c(209/(209+91), (578/(578+122)))
roc.qda
roc.qda <- roc(german_data$Default, qda.pred$posterior)
View(qda.pred)
View(qda.pred$posterior)
roc.qda <- roc(german_data$Default, qda.pred$posterior[,1])
roc.qda
plot(roc.knn, legacy.axes=T)
plot(roc.qda, legacy.axes=T)
plot(roc.knn, legacy.axes=T)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
1 - mean(qda.pred$class == german_data$Default)
table(qda.pred$class, german_data$Default)
c(209/(209+91), (578/(578+122)))
roc.qda <- roc(german_data$Default, qda.pred$posterior[,1])
roc.qda
plot(roc.qda, legacy.axes=T)
qda_misclass <- 0
for(i in nrow(german_data)){
q_fit <- qda(Default ~ ., data=german_data[-i, ])
q_pred <- predict(q_fit, german_data[i,])
err <- 1 - (q_pred == german_data[i,]$Default)
qda_misclass <- qda_misclass + err
}
for(i in nrow(german_data)){
q_fit <- qda(Default ~ ., data=german_data[-i, ])
q_pred <- predict(q_fit, german_data[i,])
err <- 1 - (q_pred$class == german_data[i,]$Default)
qda_misclass <- qda_misclass + err
}
(qda_misclass/nrow(german_data))
q_pred$class == german_data[i,]$Default
table(classifier_knn, german_data$Default)
qda.fit <- qda(Default ~ ., data = german_data)
View(qda.fit)
qda.pred <- predict(qda.fit, german_data)
View(qda.pred)
1 - mean(qda.pred$class == german_data$Default)
table(qda.pred$class, german_data$Default)
table(classifier_knn, german_data$Default)
c(25/(25+275), (689/(689+11)))
roc.qda <- roc(german_data$Default, qda.pred$posterior[,1])
roc.qda
qda_misclass <- 0
qda_misclass <- 0
for(i in nrow(german_data)){
q_fit <- qda(Default ~ ., data=german_data[-i, ])
q_pred <- predict(q_fit, german_data[i,])
err <- 1 - (q_pred$class == german_data[i,]$Default)
qda_misclass <- qda_misclass + err
}
(qda_misclass/nrow(german_data))
german_data
qda_misclass <- 0
for(i in 1:nrow(german_data)){
q_fit <- qda(Default ~ ., data=german_data[-i, ])
q_pred <- predict(q_fit, german_data[i,])
err <- 1 - (q_pred$class == german_data[i,]$Default)
qda_misclass <- qda_misclass + err
}
(qda_misclass/nrow(german_data))
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
knn_probs <- attr(classifier_knn, "prob")
roc.knn <- roc(german_data$Default, knn_probs)
roc.knn
plot(roc.knn, legacy.axes=T)
table(classifier_knn, german_data$Default)
german_data <- read.csv("germancredit.csv", stringsAsFactors = T)
################################################################################
################################################################################
lda.fit <- lda(Default ~ ., data=german_data)
View(lda.fit)
lda.pred <- predict(lda.fit, german_data)
View(lda.pred)
1 - mean(lda.pred$class == german_data$Default)
table(lda.pred$class, german_data$Default)
c(162/(162+138), 615/(615+85))
lda.pred$posterior
roc.lda
roc.lda <- roc(german_data$Default, lda.pred$posterior[,1])
roc.lda
plot(roc.lda, legacy.axes=T)
lda_misclass <- 0
for(i in 1:nrow(german_data)){
l_fit <- lda(Default ~ ., data=german_data[-i, ])
l_pred <- predict(l_fit, german_data[i,])
err <- 1 - (l_pred$class == german_data[i,]$Default)
lda_misclass <- lda_misclass + err
}
(lda_misclass/nrow(german_data))
summary(all_lr)
partial_lr <- glm(Default ~ checkingstatus1A14 + purposeA41 + purposeA43 + savingsA65 + installment)
partial_lr <- glm(Default ~ checkingstatus1A14 + purposeA41 + purposeA43 + savingsA65 + installment, data = german_data, family = "binomial")
partial_lr <- glm(formula = Default ~ checkingstatus1A14 + purposeA41 + purposeA43 + savingsA65 + installment, data = german_data, family = "binomial")
partial_lr <- glm(formula = Default ~  purposeA41 + purposeA43 + savingsA65 + installment, data = german_data, family = "binomial")
?glm
german_data
all_lr <- glm(Default ~ ., data = german_data, family = "binomial")
summary(all_lr)
partial_lr <- glm(Default ~ checkingstatus1 + purpose + savings + installment, data = german_data, family = "binomial")
summary(all_lr)
summary(partial_lr)
partial_lr <- glm(Default ~ checkingstatus1 + savings + installment, data = german_data, family = "binomial")
summary(partial_lr)
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
1 - mean(partial_lr.pred == german_data$Default)
1 - mean(all_lr.pred == german_data$Default)
partial_lr <- glm(Default ~ checkingstatus1 + savings + purpose + installment, data = german_data, family = "binomial")
summary(partial_lr)
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
1 - mean(partial_lr.pred == german_data$Default)
partial_lr <- glm(Default ~ checkingstatus1 + savings + installment, data = german_data, family = "binomial")
summary(partial_lr)
anova(partial_lr, all_lr, test = "Chisq")
partial_lr <- glm(Default ~ checkingstatus1 + savings + installment + purpose, data = german_data, family = "binomial")
all_lr <- glm(Default ~ ., data = german_data, family = "binomial")
anova(partial_lr, all_lr, test = "Chisq")
summary(all_lr)
library(boot)
library(e1071)
library(pROC)
library(class)
library(MASS)
german_data <- read.csv("germancredit.csv", stringsAsFactors = T)
all_lr <- glm(Default ~ ., data = german_data, family = "binomial")
summary(all_lr)
partial_lr <- glm(Default ~ -checkingstatus1 + savings + installment + purpose, data = german_data, family = "binomial")
summary(partial_lr)
anova(partial_lr, all_lr, test = "Chisq")
summary(all_lr)
partial_lr <- glm(Default ~ -tele - liable - job - cards - housing - property - age - residence - employ, data = german_data, family = "binomial")
summary(partial_lr)
summary(partial_lr)
partial_lr <- glm(Default ~ checkingstatus1 -tele - liable - job - cards - housing - property - age - residence - employ, data = german_data, family = "binomial")
summary(partial_lr)
anova(partial_lr, all_lr, test = "Chisq")
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
1 - mean(partial_lr.pred == german_data$Default)
summary(all_lr)
partial_lr <- glm(Default ~ checkingstatus1 + history + savings + installment + purpose, data = german_data, family = "binomial")
summary(partial_lr)
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
1 - mean(partial_lr.pred == german_data$Default)
anova(partial_lr, all_lr, test = "Chisq")
partial_lr <- glm(Default ~ checkingstatus1 + history + savings + installment, data = german_data, family = "binomial")
summary(partial_lr)
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
1 - mean(partial_lr.pred == german_data$Default)
anova(partial_lr, all_lr, test = "Chisq")
partial_lr <- glm(Default ~ checkingstatus1 + history + savings + installment + duration + purpose + otherplans, data = german_data, family = "binomial")
summary(partial_lr)
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
1 - mean(partial_lr.pred == german_data$Default)
# Dropped variables are still significant, but model still seems to be fair in its interpretation
anova(partial_lr, all_lr, test = "Chisq")
nrow(german_data)
str(german_data)
hist(german_data$Default)
pie(table(german_data$Default))
boxplot(german_data$checkingstatus1, german_data$Default)
all_lr <- glm(Default ~ ., data = german_data, family = "binomial")
boxplot(german_data$checkingstatus1, german_data$Default)
boxplot(german_data$history, german_data$Default)
boxplot(german_data$purpose, german_data$Default)
boxplot(german_data$savings, german_data$Default)
boxplot(german_data$employ, german_data$Default)
boxplot(german_data$status, german_data$Default)
boxplot(german_data$others, german_data$Default)
View(housing)
boxplot(Default ~ checkingstatus1, data = german_data)
boxplot(Default ~ history, data = german_data)
boxplot(Default ~ purpose, data = german_data)
boxplot(Default ~ savings, data = german_data)
boxplot(Default ~ employ, data = german_data)
boxplot(Default ~ status, data = german_data)
boxplot(Default ~ others, data = german_data)
boxplot(Default ~ property, data = german_data)
boxplot(Default ~ otherplans, data = german_data)
?barplot
barplot(Default ~ checkingstatus1, data = german_data)
barplot(checkingstatus1, data = german_data)
barplot(german_data$checkingstatus1, data = german_data)
barplot(german_data$checkingstatus1)
checkingstatus1
german_data$checkingstatus1
barplot(table(german_data$checkingstatus1))
nrow(german_data)
str(german_data)
pie(table(german_data$Default))
table(german_data$Default)
boxplot(Default ~ history, data = german_data)
barplot(table(german_data$checkingstatus1))
library(boot)
library(e1071)
library(pROC)
library(class)
library(MASS)
all_lr <- glm(Default ~ ., data = german_data, family = "binomial")
roc.all_lr <- roc(german_data$Default, all_lr.prob)
roc.all_lr
plot(roc.all_lr, legacy.axes=T)
all_lr.prob <- predict(all_lr, type="response")
all_lr.pred <- ifelse(all_lr.prob >= 0.5, 1, 0)
roc.all_lr <- roc(german_data$Default, all_lr.prob)
roc.all_lr
plot(roc.all_lr, legacy.axes=T)
roc.all_lr
partial_lr <- glm(Default ~ checkingstatus1 + history + savings + installment + duration + purpose + otherplans, data = german_data, family = "binomial")
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
roc.part_lr <- roc(german_data$Default, part_lr.prob)
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
roc.part_lr <- roc(german_data$Default, partial_lr.prob)
roc.part_lr
plot(roc.part_lr, legacy.axes=T)
################################################################################
################################################################################
lda.fit <- lda(Default ~ ., data=german_data)
lda.pred <- predict(lda.fit, german_data)
roc.lda <- roc(german_data$Default, lda.pred$posterior[,1])
roc.lda
plot(roc.lda, legacy.axes=T)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
roc.qda <- roc(german_data$Default, qda.pred$posterior[,1])
roc.qda
plot(roc.qda, legacy.axes=T)
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
knn_probs <- attr(classifier_knn, "prob")
###############################################################################
###############################################################################
knn.cross <- tune.knn(x = german_data[,-1], y = as.factor(german_data[,1]), k = 1:200, tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
################################################################################
################################################################################
german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)] <- sapply(german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)], as.numeric)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
roc.qda <- roc(german_data$Default, qda.pred$posterior[,1])
roc.qda
german_data <- read.csv("germancredit.csv", stringsAsFactors = T)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
roc.qda <- roc(german_data$Default, qda.pred$posterior[,1])
roc.qda
plot(roc.qda, legacy.axes=T)
################################################################################
################################################################################
german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)] <- sapply(german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)], as.numeric)
###############################################################################
###############################################################################
knn.cross <- tune.knn(x = german_data[,-1], y = as.factor(german_data[,1]), k = 1:200, tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
summary(knn.cross)
optim_K <- 30
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
knn_probs <- attr(classifier_knn, "prob")
1 - mean(classifier_knn == german_data$Default)
table(classifier_knn, german_data$Default)
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
knn_probs <- attr(classifier_knn, "prob")
1 - mean(classifier_knn == german_data$Default)
table(classifier_knn, german_data$Default)
roc.knn <- roc(german_data$Default, knn_probs)
roc.knn
plot(roc.knn, legacy.axes=T)
optim_K <- 38
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
knn_probs <- attr(classifier_knn, "prob")
roc.knn <- roc(german_data$Default, knn_probs)
roc.knn
plot(roc.knn, legacy.axes=T)
german_data <- read.csv("germancredit.csv", stringsAsFactors = T)
all_lr <- glm(Default ~ ., data = german_data, family = "binomial")
partial_lr <- glm(Default ~ checkingstatus1 + history + savings + installment + duration + purpose + otherplans, data = german_data, family = "binomial")
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
1 - mean(partial_lr.pred == german_data$Default)
1 - mean(all_lr.pred == german_data$Default)
all_lr.prob <- predict(all_lr, type="response")
all_lr.pred <- ifelse(all_lr.prob >= 0.5, 1, 0)
1 - mean(all_lr.pred == german_data$Default)
part_lr.err <- cv.glm(german_data, partial_lr, cost, K=nrow(german_data))
cost <- function(r, pi = 0){mean(abs(r - pi) > 0.5)}
part_lr.err <- cv.glm(german_data, partial_lr, cost, K=nrow(german_data))
partial_lr.err$delta
part_lr.err$delta
all_lr.err <- cv.glm(german_data, all_lr, cost, K=nrow(german_data))
all_lr.err$delta
################################################################################
################################################################################
lda.fit <- lda(Default ~ ., data=german_data)
lda.pred <- predict(lda.fit, german_data)
1 - mean(lda.pred$class == german_data$Default)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
1 - mean(qda.pred$class == german_data$Default)
qda.fit <- qda(Default ~ ., data = german_data)
qda.pred <- predict(qda.fit, german_data)
1 - mean(qda.pred$class == german_data$Default)
1 - mean(classifier_knn == german_data$Default)
###############################################################################
###############################################################################
german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)] <- sapply(german_data[,c(2,4,5,7,8,10,11,13,15,16,18,20,21)], as.numeric)
knn.cross <- tune.knn(x = german_data[,-1], y = as.factor(german_data[,1]), k = 1:200, tunecontrol=tune.control(sampling = "cross"), cross=nrow(german_data))
summary(knn.cross)
optim_K <- 38
classifier_knn <- knn(train = german_data[,-1],
test = german_data[,-1],
cl = german_data$Default,
k = optim_K, prob=T)
knn_probs <- attr(classifier_knn, "prob")
1 - mean(classifier_knn == german_data$Default)
table(partial_lr.pred, german_data$Default)
c(146/(146+154), (633/(633+67)))
table(all_lr.pred, german_data$Default)
c(160/(160+140), (626/(626+74)))
table(lda.pred$class, german_data$Default)
c(162/(162+138), 615/(615+85))
table(qda.pred$class, german_data$Default)
c(209/(209+91), (578/(578+122)))
table(classifier_knn, german_data$Default)
c(25/(25+275), (689/(689+11)))
lda_misclass <- 0
for(i in 1:nrow(german_data)){
l_fit <- lda(Default ~ ., data=german_data[-i, ])
l_pred <- predict(l_fit, german_data[i,])
err <- 1 - (l_pred$class == german_data[i,]$Default)
lda_misclass <- lda_misclass + err
}
(lda_misclass/nrow(german_data))
qda_misclass <- 0
for(i in 1:nrow(german_data)){
q_fit <- qda(Default ~ ., data=german_data[-i, ])
q_pred <- predict(q_fit, german_data[i,])
err <- 1 - (q_pred$class == german_data[i,]$Default)
qda_misclass <- qda_misclass + err
}
(qda_misclass/nrow(german_data))
# Confusion matrix and sensitivity, specificity provided
table(partial_lr.pred, german_data$Default)
summary(partial_lr)
# Produce a logistic regression model that uses predictors that appeared to have a very low p-value in our previous model
partial_lr <- glm(Default ~ checkingstatus1 + history + savings + installment + duration + otherplans, data = german_data, family = "binomial")
summary(partial_lr)
# Dropped variables are still significant, but model still seems to be fair in its interpretation
anova(partial_lr, all_lr, test = "Chisq")
# Calculate probabilities and predictions for our partial logistic regression model
partial_lr.prob <- predict(partial_lr, type="response")
partial_lr.pred <- ifelse(partial_lr.prob >= 0.5, 1, 0)
# Error rate of partial logistic regression model
1 - mean(partial_lr.pred == german_data$Default)
# Confusion matrix and sensitivity, specificity provided
table(partial_lr.pred, german_data$Default)
c(146/(146+154), (633/(633+67)))
c(130/(130+170), (625/(625+75)))
part_lr.err <- cv.glm(german_data, partial_lr, cost, K=nrow(german_data))
part_lr.err$delta
summary(partial_lr)
coef(partial_lr)
cor(german_data$Default, german_data$checkingstatus1)
cor(log(german_data$Default), german_data$checkingstatus1)
cor(german_data$Default, german_data$checkingstatus1)
cor(german_data)
cor(german_data)$Default
cor(german_data)
str(cor(german_data))
cor(german_data)[,1]
str(work)
str(Auto)
library(boot)
library(e1071)
library(pROC)
library(class)
library(MASS)
str(Auto)
library(ISLR)
str(Auto)
str(work)
fit1 <- lm(mpg ~ ., data=Auto)
summary(fit1)
fit1 <- lm(mpg ~ . - name, data=Auto)
summary(fit1)
fit2 <- lm(mpg ~ . - name - acceleration)
fit2 <- lm(mpg ~ . - name - acceleration, data=Auto)
anova(fit1, fit2)
fit2 <- lm(mpg ~ . - name - acceleration - cylinders, data=Auto)
anova(fit1, fit2)
